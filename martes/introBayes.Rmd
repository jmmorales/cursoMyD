---
output:
  knitrBootstrap::bootstrap_document:
    title: "intro"
    theme: cosmo
    highlight: Solarized - Light
    theme.chooser: TRUE
    highlight.chooser: TRUE
---

```{r, echo=FALSE}
library(knitr)
options(figure_counter = FALSE)
opts_knit$set(eval.after='fig.cap')
knitr::opts_chunk$set(tidy=TRUE, echo=TRUE, warning=FALSE, message=FALSE, dev='svg')
```

# Análisis Bayesiano

Los análisis Bayesianos son similares a los que vimos en [máxima verosimilitud](http://rpubs.com/pajaro/mle) en el sentido que dependen explícitamente de modelos probabilísticos para los datos. Pero la gran diferencia es que con Bayes, obtenemos distribuciones de probabilidades para todas las cantidades **no observadas**, incluyendo parámetros, valores perdidos o nuevas observaciones. De esta manera, los análisis Bayesianos nos permiten **cuantificar incertidumbre** y armar modelos realistas que tienen en cuenta por ejemplo observaciones imperfectas. 

Como vimos en la teórica, la regla de Bayes planteada en términos de datos y parámetros es:

$$
p(\boldsymbol{\theta} \lvert \boldsymbol{y}) = \frac{p(\boldsymbol{y} \lvert \boldsymbol{\theta}) p(\boldsymbol{\theta)}}{\int p(\boldsymbol{y} \lvert \boldsymbol{\theta)} d \boldsymbol{\theta} }
$$

Es decir que la probabilidad *posterior* de los parámetros **$\theta$** dado que observamos los datos **$y$** es igual al likelihood por las previas dividido la probabilidad de los datos. La función de likelihood nos da la probabilidad de observar los datos condicional al valor de los parámetros ( $p( \textbf{y} \lvert$ **$\theta$** ) ) y la previa de los parámetros ( $p($ **$\theta$**) ) refleja los posibles valores de los parámetros de acuerdo con nuestras creencias previas, o los resultados de estudios anteriores, o lo que nos parece que tiene sentido para el sistema de estudio. Finalmente la probabilidad total de los datos se obtiene integrando la función de lilkelihood sobre los posibles valores de los parámetros. Como veremos más adelante, los análisis Bayesianos combinados con métodos numéricos permiten analizar modelos con muchos parámetros y niveles de variabilidad pero primero vamos a empezar por casos simples donde podemos calcular las posteriores directamente. 

## Previas Conjugadas

Para algunos casos es posible resolver analícamente la ecuación de la regla de Bayes. Por ejemplo, si modelamos a la probabilidad de los datos con una Binomial y usamos a un distribución Beta para la previa de la probabilidad de éxito de la Binomial, la posterior es otra distribución Beta pero actualizada en base a las observaciones. Se dice entonces que la distribución Beta es la **conjugada** de la Binomial. Veamos un ejemplo con los datos de Quintral. Previamente vimos como calcular la tasa de remoción por frutos usando [MLE](http://rpubs.com/pajaro/mle). Para hacer un análisis equivalente pero bajo el enfoque Bayesiano podemos definir a la previa de la tasa de remoción por fruto con una distribución Beta con parámetros $\alpha$ y $\beta$ y actualizar los valores de estos parámetro en función de la cantidad de éxitos y fracasos obervados. La posterior de la tasa de remoción por fruto es entonces una Beta con $\alpha = \sum y$ y $\beta = \sum (n-y)$ donde $y$ representa a los frutos removidos de los $n$ disponibles. Veamos como hacer esto en `R`. 

Primero cargamos los datos y vemos de qué se trata (son los mismos que usamos para uno de los ejemplos de MLE)
```{r}
url <- "https://github.com/jmmorales/cursoMyD/raw/master/Data/quintral.txt"
quintral <- read.table(url, header = TRUE)
str(quintral)
```
Ahora definimos la previa para la tasa de remoción por fruto como una Beta(1,1) que equivale a no tener observaciones previas. Vemos entonces que la previa es *chata* o *no-informativa*:

```{r}
alpha <- 1
beta  <- 1

x <- seq(from = 0, to = 1, by = 0.01) 
plot(x, dbeta(x, alpha, beta), type = "l", xlab = "tasa de remoción", ylab = "densidad de probabilidad", cex.lab=1.5, cex.axis=1.5, las=1)
```

Para calcular la posterior de la tasa de remoción por fruto considerando solamente la primera observación hacemos:
```{r}
pos1 <- dbeta(x, alpha + sum(quintral$Removidos[1]) , beta + sum((quintral$Frutos[1] - quintral$Removidos[1])))

plot(x, pos1, type = "l", lwd=3, col="gray", xlab =  "tasa remoción", ylab = "densidad de probabilidad", cex.lab=1.5, cex.axis=1.5, las=1)
lines(x, dbeta(x, alpha, beta), lwd=3)
abline(v = quintral$Removidos[1]/quintral$Frutos[1], lty=3, lwd=3)
text(0.75,5,"posterior",col="darkgray",adj=0, cex = 1.5)
text(0.55,5.5, "datos", cex = 1.5)
text(0.1,1.5, "previa", cex = 1.5)
```

¿Qué pasa si incluimos más observaciones? Por ejemplo 10:

```{r}
plot(x, dbeta(x, alpha + sum(quintral$Removidos[1:10]) , beta + sum((quintral$Frutos[1:10] - quintral$Removidos[1:10]))), type = "l", xlab = "tasa de remoción", lwd=3, col="darkgray", ylab = "densidad de probabilidad", cex.lab=1.5, cex.axis=1.5, las=1)
lines(x, dbeta(x, alpha, beta), lwd=3)
text(0.75,15,"posterior",col="darkgray",adj=0, cex = 1.5)
text(0.1,2.5,"previa", cex = 1.5)
```

Ahora con todos los datos
```{r}
x <- seq(from = 0, to = 1, by = 0.001)
pos = dbeta(x, alpha + sum(quintral$Removidos) , beta + sum((quintral$Frutos - quintral$Removidos)))
plot(x,pos, type="l", xlab = "tasa de remoción", lwd=3, col="darkgray", ylab = "densidad de probabilidad", cex.lab=1.5, cex.axis=1.5, las=1)
lines(x, dbeta(x,alpha,beta), lwd = 3)
text(0.65,35,"posterior",col="darkgray",adj=0, cex = 1.5)
text(0.1,5,"previa", cex = 1.5)
```

Al igual que como vimos con MLE, cuantas más observaciones tenemos, menor es la incertidumbre alrededor del valor de tasa de remoción por fruto.

Podemos usar las funciones `pbeta` y `qbeta` para responder preguntas acerca de la posterior. Por ejemplo, la probabilidad de que la tasa de remoción de frutos sea $<= 0.6$ es
`pbeta(0.6, alpha + sum(quintral$Removidos), beta + sum((quintral$Frutos - quintral$Removidos)))` = `r pbeta(0.6, alpha + sum(quintral$Removidos), beta + sum((quintral$Frutos - quintral$Removidos)))`

El intervalo del 95% para la tasa de remoción de frutos es 
```{r}
qbeta(c(0.025,0.975), alpha + sum(quintral$Removidos), beta + sum((quintral$Frutos - quintral$Removidos)))
```

Para calcular el intrevalo de credibilidad podemos usar la función `tcredint` del paquete de `R` que acompaña al [libro de Bolker](http://ms.mcmaster.ca/~bolker/emdbook/index.html).

```{r}
library(emdbook)
tcredint("beta",list(shape1= alpha + sum(quintral$Removidos), shape2 = beta + sum((quintral$Frutos - quintral$Removidos))), verbose = TRUE)
```

***

### Ejercicios

1. Calcular las posteriores de las tasas de remoción de frutos para los distintos sitios de muestreo.

2. Calcular los intervalos de credibilidad de las tasas de remoción de frutos para cada sitio y ver si hay superposición entre las estimaciones para bosque continuo y las de los sitios de bosque fragmentado.

***

```{r}
sessionInfo()
```

***

[Juan Manuel Morales](https://sites.google.com/site/pajarom/). 6 de Septiembre del 2015. ültima actualización: `r Sys.Date()`